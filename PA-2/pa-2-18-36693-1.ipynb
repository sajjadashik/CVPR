{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-27T14:58:59.506951Z","iopub.execute_input":"2021-06-27T14:58:59.50743Z","iopub.status.idle":"2021-06-27T14:59:37.995152Z","shell.execute_reply.started":"2021-06-27T14:58:59.507332Z","shell.execute_reply":"2021-06-27T14:59:37.994473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom time import time\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm, trange\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-27T14:59:37.996441Z","iopub.execute_input":"2021-06-27T14:59:37.996766Z","iopub.status.idle":"2021-06-27T14:59:43.737694Z","shell.execute_reply.started":"2021-06-27T14:59:37.996733Z","shell.execute_reply":"2021-06-27T14:59:43.736851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\ntest_dir = '../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test'\nclasses = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\nplt.figure(figsize=(32, 32))\nfor i in range (0,29):\n    plt.subplot(7,6,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    path = train_dir + \"/{0}/{0}1.jpg\".format(classes[i])\n    img = plt.imread(path)\n    plt.imshow(img)\n    plt.xlabel(classes[i])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-27T14:59:43.739498Z","iopub.execute_input":"2021-06-27T14:59:43.739829Z","iopub.status.idle":"2021-06-27T14:59:46.224891Z","shell.execute_reply.started":"2021-06-27T14:59:43.739794Z","shell.execute_reply":"2021-06-27T14:59:46.224138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(train_dir):\n    images = []\n    labels = []\n    size = 32,32\n    index = -1\n    for folder in tqdm(os.listdir(train_dir),desc='Overall Progress'):\n        index +=1\n        print('Folder : '+classes[index])\n        for image in tqdm(os.listdir(train_dir + \"/\" + folder)):\n            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n            temp_img = cv2.resize(temp_img, size)\n            images.append(temp_img)\n            labels.append(index)\n    \n    images = np.array(images)\n    images = images.astype('float32')/255.0\n    labels = utils.to_categorical(labels)\n    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.1)\n    \n    print('Loaded', len(x_train),'images for training,','Train data shape =', x_train.shape)\n    print('Loaded', len(x_test),'images for testing','Test data shape =', x_test.shape)\n    \n    return x_train, x_test, y_train, y_test\n\nstart = time()\nx_train, x_test, y_train, y_test = load_data(train_dir)\nprint('Loading:', time() - start)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T14:59:46.226215Z","iopub.execute_input":"2021-06-27T14:59:46.226665Z","iopub.status.idle":"2021-06-27T15:06:42.779681Z","shell.execute_reply.started":"2021-06-27T14:59:46.226629Z","shell.execute_reply":"2021-06-27T15:06:42.778816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Implimenting VGG16 Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(input_shape=(32,32,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=4096,activation=\"relu\"))\n#model.add(Dense(512, activation='sigmoid'))\nmodel.add(Dense(29, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:06:42.780946Z","iopub.execute_input":"2021-06-27T15:06:42.781276Z","iopub.status.idle":"2021-06-27T15:06:44.903915Z","shell.execute_reply.started":"2021-06-27T15:06:42.781248Z","shell.execute_reply":"2021-06-27T15:06:44.903091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = 29\nbatch = 128\nepochs = 2\nlearning_rate = 0.0001\n\nmodel.summary()\n\nadam = Adam(lr=learning_rate)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n\nstart = time()\nhistory = model.fit(x_train, y_train, batch_size=batch, epochs=epochs, validation_split=0.1, shuffle = True, verbose=1)\ntrain_time = time() - start\nprint('\\nTrain time: ', train_time)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:06:44.905148Z","iopub.execute_input":"2021-06-27T15:06:44.905485Z","iopub.status.idle":"2021-06-27T15:13:27.958358Z","shell.execute_reply.started":"2021-06-27T15:06:44.905452Z","shell.execute_reply":"2021-06-27T15:13:27.95752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  plt.figure(figsize=(12, 12))\n  plt.subplot(3, 2, 1)\n  plt.plot(history.history['accuracy'], label = 'train_accuracy')\n  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n  plt.xlabel('epoch')\n  plt.ylabel('accuracy')\n  plt.legend()\n  plt.subplot(3, 2, 2)\n  plt.plot(history.history['loss'], label = 'train_loss')\n  plt.plot(history.history['val_loss'], label = 'val_loss')\n  plt.xlabel('epoch')\n  plt.ylabel('accuracy')\n  plt.legend()\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:16:16.168569Z","iopub.execute_input":"2021-06-27T15:16:16.168885Z","iopub.status.idle":"2021-06-27T15:16:16.42888Z","shell.execute_reply.started":"2021-06-27T15:16:16.168856Z","shell.execute_reply":"2021-06-27T15:16:16.428107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  start = time()\n  test_loss, test_acc = model.evaluate(x_test, y_test)\n  test_time = time() - start\n \n  print('Test accuracy:', test_acc)\n  print('Test loss:', test_loss)\n  print('Test time: ', test_time)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T15:16:39.942794Z","iopub.execute_input":"2021-06-27T15:16:39.943134Z"},"trusted":true},"execution_count":null,"outputs":[]}]}